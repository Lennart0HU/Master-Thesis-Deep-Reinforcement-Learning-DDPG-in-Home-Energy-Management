{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "using CSV, DataFrames, Dates, TimeZones\n",
    "\n",
    "ENV[\"COLUMNS\"] = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Charger06\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ID = \"Charger06\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35040-element Vector{ZonedDateTime}:\n",
       " 2020-11-01T00:00:00+01:00\n",
       " 2020-11-01T00:15:00+01:00\n",
       " 2020-11-01T00:30:00+01:00\n",
       " 2020-11-01T00:45:00+01:00\n",
       " 2020-11-01T01:00:00+01:00\n",
       " 2020-11-01T01:15:00+01:00\n",
       " 2020-11-01T01:30:00+01:00\n",
       " 2020-11-01T01:45:00+01:00\n",
       " 2020-11-01T02:00:00+01:00\n",
       " 2020-11-01T02:15:00+01:00\n",
       " ⋮\n",
       " 2021-10-31T21:45:00+01:00\n",
       " 2021-10-31T22:00:00+01:00\n",
       " 2021-10-31T22:15:00+01:00\n",
       " 2021-10-31T22:30:00+01:00\n",
       " 2021-10-31T22:45:00+01:00\n",
       " 2021-10-31T23:00:00+01:00\n",
       " 2021-10-31T23:15:00+01:00\n",
       " 2021-10-31T23:30:00+01:00\n",
       " 2021-10-31T23:45:00+01:00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Read the CSV file from the specified path\n",
    "df = CSV.read(\"data/charger_battery_data_$ID.csv\", DataFrame)\n",
    "\n",
    "# Filter the data\n",
    "df = df[:, [:timestamp, :e_consumption, :e_production, :e_charger, :h_countdown, :soc_ev]]\n",
    "\n",
    "df.e_consumption = df.e_consumption / 1000\n",
    "df.e_production = df.e_production / 1000\n",
    "df.e_charger = df.e_charger / 1000\n",
    "\n",
    "# Parse the timestamps with timezone offset\n",
    "timestamps = ZonedDateTime.(df.timestamp, DateFormat(\"yyyy-mm-dd HH:MM:SSzzzz\"))\n",
    "\n",
    "# Shift the timestamps one hour ahead\n",
    "timestamps = timestamps .- Hour(1)\n",
    "\n",
    "# Replace the timestamp column in the DataFrame with the shifted timestamps\n",
    "df.timestamp = timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>timestamp</th><th>e_consumption</th><th>e_production</th><th>e_charger</th><th>h_countdown</th><th>soc_ev</th></tr><tr><th></th><th>ZonedDa…</th><th>Float64</th><th>Float64</th><th>Float64?</th><th>Float64</th><th>Float64</th></tr></thead><tbody><p>35,040 rows × 6 columns</p><tr><th>1</th><td>2020-11-01T00:00:00+01:00</td><td>0.542</td><td>0.0</td><td><em>missing</em></td><td>-1.0</td><td>1.0</td></tr><tr><th>2</th><td>2020-11-01T00:15:00+01:00</td><td>0.539</td><td>0.0</td><td><em>missing</em></td><td>-1.0</td><td>1.0</td></tr><tr><th>3</th><td>2020-11-01T00:30:00+01:00</td><td>0.53</td><td>0.0</td><td><em>missing</em></td><td>-1.0</td><td>1.0</td></tr><tr><th>4</th><td>2020-11-01T00:45:00+01:00</td><td>0.517</td><td>0.0</td><td><em>missing</em></td><td>-1.0</td><td>1.0</td></tr><tr><th>5</th><td>2020-11-01T01:00:00+01:00</td><td>0.064</td><td>0.0</td><td><em>missing</em></td><td>-1.0</td><td>1.0</td></tr><tr><th>6</th><td>2020-11-01T01:15:00+01:00</td><td>0.064</td><td>0.0</td><td><em>missing</em></td><td>-1.0</td><td>1.0</td></tr><tr><th>7</th><td>2020-11-01T01:30:00+01:00</td><td>0.052</td><td>0.0</td><td><em>missing</em></td><td>-1.0</td><td>1.0</td></tr><tr><th>8</th><td>2020-11-01T01:45:00+01:00</td><td>0.06</td><td>0.0</td><td><em>missing</em></td><td>-1.0</td><td>1.0</td></tr><tr><th>9</th><td>2020-11-01T02:00:00+01:00</td><td>0.073</td><td>0.0</td><td><em>missing</em></td><td>-1.0</td><td>1.0</td></tr><tr><th>10</th><td>2020-11-01T02:15:00+01:00</td><td>0.065</td><td>0.0</td><td><em>missing</em></td><td>-1.0</td><td>1.0</td></tr><tr><th>11</th><td>2020-11-01T02:30:00+01:00</td><td>0.093</td><td>0.0</td><td><em>missing</em></td><td>-1.0</td><td>1.0</td></tr><tr><th>12</th><td>2020-11-01T02:45:00+01:00</td><td>0.491</td><td>0.0</td><td><em>missing</em></td><td>-1.0</td><td>1.0</td></tr><tr><th>13</th><td>2020-11-01T03:00:00+01:00</td><td>0.51</td><td>0.0</td><td><em>missing</em></td><td>-1.0</td><td>1.0</td></tr><tr><th>14</th><td>2020-11-01T03:15:00+01:00</td><td>0.543</td><td>0.0</td><td><em>missing</em></td><td>-1.0</td><td>1.0</td></tr><tr><th>15</th><td>2020-11-01T03:30:00+01:00</td><td>0.559</td><td>0.0</td><td><em>missing</em></td><td>-1.0</td><td>1.0</td></tr><tr><th>16</th><td>2020-11-01T03:45:00+01:00</td><td>0.574</td><td>0.0</td><td><em>missing</em></td><td>-1.0</td><td>1.0</td></tr><tr><th>17</th><td>2020-11-01T04:00:00+01:00</td><td>0.595</td><td>0.0</td><td><em>missing</em></td><td>-1.0</td><td>1.0</td></tr><tr><th>18</th><td>2020-11-01T04:15:00+01:00</td><td>0.5</td><td>0.0</td><td><em>missing</em></td><td>-1.0</td><td>1.0</td></tr><tr><th>19</th><td>2020-11-01T04:30:00+01:00</td><td>0.532</td><td>0.0</td><td><em>missing</em></td><td>-1.0</td><td>1.0</td></tr><tr><th>20</th><td>2020-11-01T04:45:00+01:00</td><td>0.535</td><td>0.0</td><td><em>missing</em></td><td>-1.0</td><td>1.0</td></tr><tr><th>21</th><td>2020-11-01T05:00:00+01:00</td><td>0.563</td><td>0.0</td><td><em>missing</em></td><td>-1.0</td><td>1.0</td></tr><tr><th>22</th><td>2020-11-01T05:15:00+01:00</td><td>1.0</td><td>0.0</td><td><em>missing</em></td><td>-1.0</td><td>1.0</td></tr><tr><th>23</th><td>2020-11-01T05:30:00+01:00</td><td>0.088</td><td>0.0</td><td><em>missing</em></td><td>-1.0</td><td>1.0</td></tr><tr><th>24</th><td>2020-11-01T05:45:00+01:00</td><td>0.05</td><td>0.0</td><td><em>missing</em></td><td>-1.0</td><td>1.0</td></tr><tr><th>&vellip;</th><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccccc}\n",
       "\t& timestamp & e\\_consumption & e\\_production & e\\_charger & h\\_countdown & soc\\_ev\\\\\n",
       "\t\\hline\n",
       "\t& ZonedDa… & Float64 & Float64 & Float64? & Float64 & Float64\\\\\n",
       "\t\\hline\n",
       "\t1 & 2020-11-01T00:00:00+01:00 & 0.542 & 0.0 & \\emph{missing} & -1.0 & 1.0 \\\\\n",
       "\t2 & 2020-11-01T00:15:00+01:00 & 0.539 & 0.0 & \\emph{missing} & -1.0 & 1.0 \\\\\n",
       "\t3 & 2020-11-01T00:30:00+01:00 & 0.53 & 0.0 & \\emph{missing} & -1.0 & 1.0 \\\\\n",
       "\t4 & 2020-11-01T00:45:00+01:00 & 0.517 & 0.0 & \\emph{missing} & -1.0 & 1.0 \\\\\n",
       "\t5 & 2020-11-01T01:00:00+01:00 & 0.064 & 0.0 & \\emph{missing} & -1.0 & 1.0 \\\\\n",
       "\t6 & 2020-11-01T01:15:00+01:00 & 0.064 & 0.0 & \\emph{missing} & -1.0 & 1.0 \\\\\n",
       "\t7 & 2020-11-01T01:30:00+01:00 & 0.052 & 0.0 & \\emph{missing} & -1.0 & 1.0 \\\\\n",
       "\t8 & 2020-11-01T01:45:00+01:00 & 0.06 & 0.0 & \\emph{missing} & -1.0 & 1.0 \\\\\n",
       "\t9 & 2020-11-01T02:00:00+01:00 & 0.073 & 0.0 & \\emph{missing} & -1.0 & 1.0 \\\\\n",
       "\t10 & 2020-11-01T02:15:00+01:00 & 0.065 & 0.0 & \\emph{missing} & -1.0 & 1.0 \\\\\n",
       "\t11 & 2020-11-01T02:30:00+01:00 & 0.093 & 0.0 & \\emph{missing} & -1.0 & 1.0 \\\\\n",
       "\t12 & 2020-11-01T02:45:00+01:00 & 0.491 & 0.0 & \\emph{missing} & -1.0 & 1.0 \\\\\n",
       "\t13 & 2020-11-01T03:00:00+01:00 & 0.51 & 0.0 & \\emph{missing} & -1.0 & 1.0 \\\\\n",
       "\t14 & 2020-11-01T03:15:00+01:00 & 0.543 & 0.0 & \\emph{missing} & -1.0 & 1.0 \\\\\n",
       "\t15 & 2020-11-01T03:30:00+01:00 & 0.559 & 0.0 & \\emph{missing} & -1.0 & 1.0 \\\\\n",
       "\t16 & 2020-11-01T03:45:00+01:00 & 0.574 & 0.0 & \\emph{missing} & -1.0 & 1.0 \\\\\n",
       "\t17 & 2020-11-01T04:00:00+01:00 & 0.595 & 0.0 & \\emph{missing} & -1.0 & 1.0 \\\\\n",
       "\t18 & 2020-11-01T04:15:00+01:00 & 0.5 & 0.0 & \\emph{missing} & -1.0 & 1.0 \\\\\n",
       "\t19 & 2020-11-01T04:30:00+01:00 & 0.532 & 0.0 & \\emph{missing} & -1.0 & 1.0 \\\\\n",
       "\t20 & 2020-11-01T04:45:00+01:00 & 0.535 & 0.0 & \\emph{missing} & -1.0 & 1.0 \\\\\n",
       "\t21 & 2020-11-01T05:00:00+01:00 & 0.563 & 0.0 & \\emph{missing} & -1.0 & 1.0 \\\\\n",
       "\t22 & 2020-11-01T05:15:00+01:00 & 1.0 & 0.0 & \\emph{missing} & -1.0 & 1.0 \\\\\n",
       "\t23 & 2020-11-01T05:30:00+01:00 & 0.088 & 0.0 & \\emph{missing} & -1.0 & 1.0 \\\\\n",
       "\t24 & 2020-11-01T05:45:00+01:00 & 0.05 & 0.0 & \\emph{missing} & -1.0 & 1.0 \\\\\n",
       "\t$\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m35040×6 DataFrame\u001b[0m\n",
       "\u001b[1m   Row \u001b[0m│\u001b[1m timestamp                 \u001b[0m\u001b[1m e_consumption \u001b[0m\u001b[1m e_production \u001b[0m\u001b[1m e_charger \u001b[0m\u001b[1m h_countdown \u001b[0m\u001b[1m soc_ev  \u001b[0m\n",
       "\u001b[1m       \u001b[0m│\u001b[90m ZonedDat…                 \u001b[0m\u001b[90m Float64       \u001b[0m\u001b[90m Float64      \u001b[0m\u001b[90m Float64?  \u001b[0m\u001b[90m Float64     \u001b[0m\u001b[90m Float64 \u001b[0m\n",
       "───────┼─────────────────────────────────────────────────────────────────────────────────────────\n",
       "     1 │ 2020-11-01T00:00:00+01:00          0.542           0.0 \u001b[90m   missing \u001b[0m        -1.0      1.0\n",
       "     2 │ 2020-11-01T00:15:00+01:00          0.539           0.0 \u001b[90m   missing \u001b[0m        -1.0      1.0\n",
       "     3 │ 2020-11-01T00:30:00+01:00          0.53            0.0 \u001b[90m   missing \u001b[0m        -1.0      1.0\n",
       "     4 │ 2020-11-01T00:45:00+01:00          0.517           0.0 \u001b[90m   missing \u001b[0m        -1.0      1.0\n",
       "     5 │ 2020-11-01T01:00:00+01:00          0.064           0.0 \u001b[90m   missing \u001b[0m        -1.0      1.0\n",
       "     6 │ 2020-11-01T01:15:00+01:00          0.064           0.0 \u001b[90m   missing \u001b[0m        -1.0      1.0\n",
       "     7 │ 2020-11-01T01:30:00+01:00          0.052           0.0 \u001b[90m   missing \u001b[0m        -1.0      1.0\n",
       "     8 │ 2020-11-01T01:45:00+01:00          0.06            0.0 \u001b[90m   missing \u001b[0m        -1.0      1.0\n",
       "   ⋮   │             ⋮                    ⋮             ⋮            ⋮           ⋮          ⋮\n",
       " 35034 │ 2021-10-31T22:15:00+01:00          0.06            0.0 \u001b[90m   missing \u001b[0m        -1.0      1.0\n",
       " 35035 │ 2021-10-31T22:30:00+01:00          0.067           0.0 \u001b[90m   missing \u001b[0m        -1.0      1.0\n",
       " 35036 │ 2021-10-31T22:45:00+01:00          0.478           0.0 \u001b[90m   missing \u001b[0m        -1.0      1.0\n",
       " 35037 │ 2021-10-31T23:00:00+01:00          0.482           0.0 \u001b[90m   missing \u001b[0m        -1.0      1.0\n",
       " 35038 │ 2021-10-31T23:15:00+01:00          0.505           0.0 \u001b[90m   missing \u001b[0m        -1.0      1.0\n",
       " 35039 │ 2021-10-31T23:30:00+01:00          0.506           0.0 \u001b[90m   missing \u001b[0m        -1.0      1.0\n",
       " 35040 │ 2021-10-31T23:45:00+01:00          0.512           0.0 \u001b[90m   missing \u001b[0m        -1.0      1.0\n",
       "\u001b[36m                                                                               35025 rows omitted\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"Column: \", \"timestamp\", \", Type: \", ZonedDateTime)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(\"Column: \", \"e_consumption\", \", Type: \", Float64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(\"Column: \", \"e_production\", \", Type: \", Float64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(\"Column: \", \"e_charger\", \", Type: \", Union{Missing, Float64})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(\"Column: \", \"h_countdown\", \", Type: \", Float64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(\"Column: \", \"soc_ev\", \", Type: \", Float64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(\"Column: \", \"timestamp\", \", Missing Values: \", 0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(\"Column: \", \"e_consumption\", \", Missing Values: \", 0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(\"Column: \", \"e_production\", \", Missing Values: \", 0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(\"Column: \", \"e_charger\", \", Missing Values: \", 28546)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(\"Column: \", \"h_countdown\", \", Missing Values: \", 0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(\"Column: \", \"soc_ev\", \", Missing Values: \", 0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for col_name in names(df)\n",
    "    display((\"Column: \", col_name, \", Type: \", eltype(df[!, col_name])))\n",
    "end\n",
    "\n",
    "for col_name in names(df)\n",
    "    missing_count = sum(ismissing.(df[!, col_name]))\n",
    "    display((\"Column: \", col_name, \", Missing Values: \", missing_count))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#describe(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resamplign from 15min intervalls to 1h intervalls. In the future, I'd like to try to work with 15min intervals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "resample (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function resample(df, time_column, interval)\n",
    "    # Round the timestamps to the nearest hour\n",
    "    df[!, time_column] = Dates.floor.(df[!, time_column], interval)\n",
    "    \n",
    "    # Define the columns to be summed\n",
    "    sum_columns = [\"e_consumption\", \"e_production\", \"e_charger\"]\n",
    "    \n",
    "    # Group by the rounded timestamps and sum the other columns\n",
    "    new_df = combine(groupby(df, time_column), sum_columns .=> (x -> sum(coalesce.(x, 0))) .=> sum_columns)\n",
    "    \n",
    "    # Handle \"h_countdown\" and \"soc_ev\" separately\n",
    "    min_values = combine(groupby(df, time_column), \"h_countdown\" => minimum => \"h_countdown\")\n",
    "    new_df = leftjoin(new_df, min_values, on=time_column)\n",
    "    \n",
    "    min_values = combine(groupby(df, time_column), \"soc_ev\" => minimum => \"soc_ev\")\n",
    "    new_df = leftjoin(new_df, min_values, on=time_column)\n",
    "\n",
    "    #Increase every value of h_countdown to the next higher integer\n",
    "    new_df.h_countdown = ceil.(new_df.h_countdown)\n",
    "\n",
    "    # Change last countdown value from -1\n",
    "    for i in 2:(nrow(new_df) )# - 1)\n",
    "        if new_df[i, :h_countdown] == -1 && new_df[(i-1), :h_countdown] == 1\n",
    "            new_df[i, :h_countdown] = 0\n",
    "        end\n",
    "    end\n",
    "\n",
    "    return new_df\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>timestamp</th><th>e_consumption</th><th>e_production</th><th>e_charger</th><th>h_countdown</th><th>soc_ev</th></tr><tr><th></th><th>ZonedDa…</th><th>Float64</th><th>Float64</th><th>Float64</th><th>Float64</th><th>Float64?</th></tr></thead><tbody><p>8,760 rows × 6 columns</p><tr><th>1</th><td>2020-11-01T00:00:00+01:00</td><td>2.128</td><td>0.0</td><td>0.0</td><td>-1.0</td><td>1.0</td></tr><tr><th>2</th><td>2020-11-01T01:00:00+01:00</td><td>0.24</td><td>0.0</td><td>0.0</td><td>-1.0</td><td>1.0</td></tr><tr><th>3</th><td>2020-11-01T02:00:00+01:00</td><td>0.722</td><td>0.0</td><td>0.0</td><td>-1.0</td><td>1.0</td></tr><tr><th>4</th><td>2020-11-01T03:00:00+01:00</td><td>2.186</td><td>0.0</td><td>0.0</td><td>-1.0</td><td>1.0</td></tr><tr><th>5</th><td>2020-11-01T04:00:00+01:00</td><td>2.162</td><td>0.0</td><td>0.0</td><td>-1.0</td><td>1.0</td></tr><tr><th>6</th><td>2020-11-01T05:00:00+01:00</td><td>1.701</td><td>0.0</td><td>0.0</td><td>-1.0</td><td>1.0</td></tr><tr><th>7</th><td>2020-11-01T06:00:00+01:00</td><td>0.258</td><td>0.147</td><td>0.0</td><td>-1.0</td><td>1.0</td></tr><tr><th>8</th><td>2020-11-01T07:00:00+01:00</td><td>0.764</td><td>0.5</td><td>0.0</td><td>-1.0</td><td>1.0</td></tr><tr><th>9</th><td>2020-11-01T08:00:00+01:00</td><td>2.059</td><td>1.161</td><td>0.0</td><td>-1.0</td><td>1.0</td></tr><tr><th>10</th><td>2020-11-01T09:00:00+01:00</td><td>0.295</td><td>1.879</td><td>0.0</td><td>-1.0</td><td>1.0</td></tr><tr><th>11</th><td>2020-11-01T10:00:00+01:00</td><td>0.591</td><td>1.361</td><td>0.0</td><td>-1.0</td><td>1.0</td></tr><tr><th>12</th><td>2020-11-01T11:00:00+01:00</td><td>1.403</td><td>1.318</td><td>0.0</td><td>-1.0</td><td>1.0</td></tr><tr><th>13</th><td>2020-11-01T12:00:00+01:00</td><td>2.389</td><td>1.133</td><td>0.0</td><td>-1.0</td><td>1.0</td></tr><tr><th>14</th><td>2020-11-01T13:00:00+01:00</td><td>2.752</td><td>1.069</td><td>0.0</td><td>-1.0</td><td>1.0</td></tr><tr><th>15</th><td>2020-11-01T14:00:00+01:00</td><td>1.248</td><td>0.433</td><td>0.0</td><td>-1.0</td><td>1.0</td></tr><tr><th>16</th><td>2020-11-01T15:00:00+01:00</td><td>0.861</td><td>0.078</td><td>0.0</td><td>-1.0</td><td>1.0</td></tr><tr><th>17</th><td>2020-11-01T16:00:00+01:00</td><td>1.692</td><td>0.0</td><td>0.0</td><td>-1.0</td><td>1.0</td></tr><tr><th>18</th><td>2020-11-01T17:00:00+01:00</td><td>0.55</td><td>0.0</td><td>0.0</td><td>-1.0</td><td>1.0</td></tr><tr><th>19</th><td>2020-11-01T18:00:00+01:00</td><td>0.871</td><td>0.0</td><td>0.0</td><td>-1.0</td><td>1.0</td></tr><tr><th>20</th><td>2020-11-01T19:00:00+01:00</td><td>2.619</td><td>0.0</td><td>0.0</td><td>-1.0</td><td>1.0</td></tr><tr><th>21</th><td>2020-11-01T20:00:00+01:00</td><td>1.68</td><td>0.0</td><td>0.0</td><td>-1.0</td><td>1.0</td></tr><tr><th>22</th><td>2020-11-01T21:00:00+01:00</td><td>0.543</td><td>0.0</td><td>0.0</td><td>-1.0</td><td>1.0</td></tr><tr><th>23</th><td>2020-11-01T22:00:00+01:00</td><td>0.26</td><td>0.0</td><td>0.0</td><td>-1.0</td><td>1.0</td></tr><tr><th>24</th><td>2020-11-01T23:00:00+01:00</td><td>0.262</td><td>0.0</td><td>0.0</td><td>-1.0</td><td>1.0</td></tr><tr><th>&vellip;</th><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccccc}\n",
       "\t& timestamp & e\\_consumption & e\\_production & e\\_charger & h\\_countdown & soc\\_ev\\\\\n",
       "\t\\hline\n",
       "\t& ZonedDa… & Float64 & Float64 & Float64 & Float64 & Float64?\\\\\n",
       "\t\\hline\n",
       "\t1 & 2020-11-01T00:00:00+01:00 & 2.128 & 0.0 & 0.0 & -1.0 & 1.0 \\\\\n",
       "\t2 & 2020-11-01T01:00:00+01:00 & 0.24 & 0.0 & 0.0 & -1.0 & 1.0 \\\\\n",
       "\t3 & 2020-11-01T02:00:00+01:00 & 0.722 & 0.0 & 0.0 & -1.0 & 1.0 \\\\\n",
       "\t4 & 2020-11-01T03:00:00+01:00 & 2.186 & 0.0 & 0.0 & -1.0 & 1.0 \\\\\n",
       "\t5 & 2020-11-01T04:00:00+01:00 & 2.162 & 0.0 & 0.0 & -1.0 & 1.0 \\\\\n",
       "\t6 & 2020-11-01T05:00:00+01:00 & 1.701 & 0.0 & 0.0 & -1.0 & 1.0 \\\\\n",
       "\t7 & 2020-11-01T06:00:00+01:00 & 0.258 & 0.147 & 0.0 & -1.0 & 1.0 \\\\\n",
       "\t8 & 2020-11-01T07:00:00+01:00 & 0.764 & 0.5 & 0.0 & -1.0 & 1.0 \\\\\n",
       "\t9 & 2020-11-01T08:00:00+01:00 & 2.059 & 1.161 & 0.0 & -1.0 & 1.0 \\\\\n",
       "\t10 & 2020-11-01T09:00:00+01:00 & 0.295 & 1.879 & 0.0 & -1.0 & 1.0 \\\\\n",
       "\t11 & 2020-11-01T10:00:00+01:00 & 0.591 & 1.361 & 0.0 & -1.0 & 1.0 \\\\\n",
       "\t12 & 2020-11-01T11:00:00+01:00 & 1.403 & 1.318 & 0.0 & -1.0 & 1.0 \\\\\n",
       "\t13 & 2020-11-01T12:00:00+01:00 & 2.389 & 1.133 & 0.0 & -1.0 & 1.0 \\\\\n",
       "\t14 & 2020-11-01T13:00:00+01:00 & 2.752 & 1.069 & 0.0 & -1.0 & 1.0 \\\\\n",
       "\t15 & 2020-11-01T14:00:00+01:00 & 1.248 & 0.433 & 0.0 & -1.0 & 1.0 \\\\\n",
       "\t16 & 2020-11-01T15:00:00+01:00 & 0.861 & 0.078 & 0.0 & -1.0 & 1.0 \\\\\n",
       "\t17 & 2020-11-01T16:00:00+01:00 & 1.692 & 0.0 & 0.0 & -1.0 & 1.0 \\\\\n",
       "\t18 & 2020-11-01T17:00:00+01:00 & 0.55 & 0.0 & 0.0 & -1.0 & 1.0 \\\\\n",
       "\t19 & 2020-11-01T18:00:00+01:00 & 0.871 & 0.0 & 0.0 & -1.0 & 1.0 \\\\\n",
       "\t20 & 2020-11-01T19:00:00+01:00 & 2.619 & 0.0 & 0.0 & -1.0 & 1.0 \\\\\n",
       "\t21 & 2020-11-01T20:00:00+01:00 & 1.68 & 0.0 & 0.0 & -1.0 & 1.0 \\\\\n",
       "\t22 & 2020-11-01T21:00:00+01:00 & 0.543 & 0.0 & 0.0 & -1.0 & 1.0 \\\\\n",
       "\t23 & 2020-11-01T22:00:00+01:00 & 0.26 & 0.0 & 0.0 & -1.0 & 1.0 \\\\\n",
       "\t24 & 2020-11-01T23:00:00+01:00 & 0.262 & 0.0 & 0.0 & -1.0 & 1.0 \\\\\n",
       "\t$\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m8760×6 DataFrame\u001b[0m\n",
       "\u001b[1m  Row \u001b[0m│\u001b[1m timestamp                 \u001b[0m\u001b[1m e_consumption \u001b[0m\u001b[1m e_production \u001b[0m\u001b[1m e_charger \u001b[0m\u001b[1m h_countdown \u001b[0m\u001b[1m soc_ev   \u001b[0m\n",
       "\u001b[1m      \u001b[0m│\u001b[90m ZonedDat…                 \u001b[0m\u001b[90m Float64       \u001b[0m\u001b[90m Float64      \u001b[0m\u001b[90m Float64   \u001b[0m\u001b[90m Float64     \u001b[0m\u001b[90m Float64? \u001b[0m\n",
       "──────┼──────────────────────────────────────────────────────────────────────────────────────────\n",
       "    1 │ 2020-11-01T00:00:00+01:00          2.128         0.0          0.0         -1.0       1.0\n",
       "    2 │ 2020-11-01T01:00:00+01:00          0.24          0.0          0.0         -1.0       1.0\n",
       "    3 │ 2020-11-01T02:00:00+01:00          0.722         0.0          0.0         -1.0       1.0\n",
       "    4 │ 2020-11-01T03:00:00+01:00          2.186         0.0          0.0         -1.0       1.0\n",
       "    5 │ 2020-11-01T04:00:00+01:00          2.162         0.0          0.0         -1.0       1.0\n",
       "    6 │ 2020-11-01T05:00:00+01:00          1.701         0.0          0.0         -1.0       1.0\n",
       "    7 │ 2020-11-01T06:00:00+01:00          0.258         0.147        0.0         -1.0       1.0\n",
       "    8 │ 2020-11-01T07:00:00+01:00          0.764         0.5          0.0         -1.0       1.0\n",
       "  ⋮   │             ⋮                    ⋮             ⋮            ⋮           ⋮          ⋮\n",
       " 8754 │ 2021-10-31T17:00:00+01:00          1.69          0.0          0.0         -1.0       1.0\n",
       " 8755 │ 2021-10-31T18:00:00+01:00          0.563         0.0          0.0         -1.0       1.0\n",
       " 8756 │ 2021-10-31T19:00:00+01:00          2.612         0.0          0.0         -1.0       1.0\n",
       " 8757 │ 2021-10-31T20:00:00+01:00          2.288         0.0          0.0         -1.0       1.0\n",
       " 8758 │ 2021-10-31T21:00:00+01:00          0.976         0.0          0.0         -1.0       1.0\n",
       " 8759 │ 2021-10-31T22:00:00+01:00          0.677         0.0          0.0         -1.0       1.0\n",
       " 8760 │ 2021-10-31T23:00:00+01:00          2.005         0.0          0.0         -1.0       1.0\n",
       "\u001b[36m                                                                                8745 rows omitted\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Resample the data to 1-hour intervals\n",
    "df_resampled = resample(df, :timestamp, Dates.Hour(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8760-element Vector{Union{Missing, Float64}}:\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " ⋮\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Change the type of the chargekwh column to Union{Missing, Float64}\n",
    "df_resampled.e_charge = convert(Vector{Union{Missing, Float64}}, df_resampled.e_charger)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>electkwh</th><th>PV_generation</th><th>chargekwh</th><th>h_countdown</th><th>soc_ev</th><th>month</th><th>day</th><th>hour</th></tr><tr><th></th><th>Float64</th><th>Float64</th><th>Float64</th><th>Float64</th><th>Float64?</th><th>Int64</th><th>Int64</th><th>Int64</th></tr></thead><tbody><p>8,760 rows × 8 columns</p><tr><th>1</th><td>2.128</td><td>0.0</td><td>0.0</td><td>-1.0</td><td>1.0</td><td>11</td><td>1</td><td>0</td></tr><tr><th>2</th><td>0.24</td><td>0.0</td><td>0.0</td><td>-1.0</td><td>1.0</td><td>11</td><td>1</td><td>1</td></tr><tr><th>3</th><td>0.722</td><td>0.0</td><td>0.0</td><td>-1.0</td><td>1.0</td><td>11</td><td>1</td><td>2</td></tr><tr><th>4</th><td>2.186</td><td>0.0</td><td>0.0</td><td>-1.0</td><td>1.0</td><td>11</td><td>1</td><td>3</td></tr><tr><th>5</th><td>2.162</td><td>0.0</td><td>0.0</td><td>-1.0</td><td>1.0</td><td>11</td><td>1</td><td>4</td></tr><tr><th>6</th><td>1.701</td><td>0.0</td><td>0.0</td><td>-1.0</td><td>1.0</td><td>11</td><td>1</td><td>5</td></tr><tr><th>7</th><td>0.258</td><td>0.147</td><td>0.0</td><td>-1.0</td><td>1.0</td><td>11</td><td>1</td><td>6</td></tr><tr><th>8</th><td>0.764</td><td>0.5</td><td>0.0</td><td>-1.0</td><td>1.0</td><td>11</td><td>1</td><td>7</td></tr><tr><th>9</th><td>2.059</td><td>1.161</td><td>0.0</td><td>-1.0</td><td>1.0</td><td>11</td><td>1</td><td>8</td></tr><tr><th>10</th><td>0.295</td><td>1.879</td><td>0.0</td><td>-1.0</td><td>1.0</td><td>11</td><td>1</td><td>9</td></tr><tr><th>11</th><td>0.591</td><td>1.361</td><td>0.0</td><td>-1.0</td><td>1.0</td><td>11</td><td>1</td><td>10</td></tr><tr><th>12</th><td>1.403</td><td>1.318</td><td>0.0</td><td>-1.0</td><td>1.0</td><td>11</td><td>1</td><td>11</td></tr><tr><th>13</th><td>2.389</td><td>1.133</td><td>0.0</td><td>-1.0</td><td>1.0</td><td>11</td><td>1</td><td>12</td></tr><tr><th>14</th><td>2.752</td><td>1.069</td><td>0.0</td><td>-1.0</td><td>1.0</td><td>11</td><td>1</td><td>13</td></tr><tr><th>15</th><td>1.248</td><td>0.433</td><td>0.0</td><td>-1.0</td><td>1.0</td><td>11</td><td>1</td><td>14</td></tr><tr><th>16</th><td>0.861</td><td>0.078</td><td>0.0</td><td>-1.0</td><td>1.0</td><td>11</td><td>1</td><td>15</td></tr><tr><th>17</th><td>1.692</td><td>0.0</td><td>0.0</td><td>-1.0</td><td>1.0</td><td>11</td><td>1</td><td>16</td></tr><tr><th>18</th><td>0.55</td><td>0.0</td><td>0.0</td><td>-1.0</td><td>1.0</td><td>11</td><td>1</td><td>17</td></tr><tr><th>19</th><td>0.871</td><td>0.0</td><td>0.0</td><td>-1.0</td><td>1.0</td><td>11</td><td>1</td><td>18</td></tr><tr><th>20</th><td>2.619</td><td>0.0</td><td>0.0</td><td>-1.0</td><td>1.0</td><td>11</td><td>1</td><td>19</td></tr><tr><th>21</th><td>1.68</td><td>0.0</td><td>0.0</td><td>-1.0</td><td>1.0</td><td>11</td><td>1</td><td>20</td></tr><tr><th>22</th><td>0.543</td><td>0.0</td><td>0.0</td><td>-1.0</td><td>1.0</td><td>11</td><td>1</td><td>21</td></tr><tr><th>23</th><td>0.26</td><td>0.0</td><td>0.0</td><td>-1.0</td><td>1.0</td><td>11</td><td>1</td><td>22</td></tr><tr><th>24</th><td>0.262</td><td>0.0</td><td>0.0</td><td>-1.0</td><td>1.0</td><td>11</td><td>1</td><td>23</td></tr><tr><th>&vellip;</th><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccccccc}\n",
       "\t& electkwh & PV\\_generation & chargekwh & h\\_countdown & soc\\_ev & month & day & hour\\\\\n",
       "\t\\hline\n",
       "\t& Float64 & Float64 & Float64 & Float64 & Float64? & Int64 & Int64 & Int64\\\\\n",
       "\t\\hline\n",
       "\t1 & 2.128 & 0.0 & 0.0 & -1.0 & 1.0 & 11 & 1 & 0 \\\\\n",
       "\t2 & 0.24 & 0.0 & 0.0 & -1.0 & 1.0 & 11 & 1 & 1 \\\\\n",
       "\t3 & 0.722 & 0.0 & 0.0 & -1.0 & 1.0 & 11 & 1 & 2 \\\\\n",
       "\t4 & 2.186 & 0.0 & 0.0 & -1.0 & 1.0 & 11 & 1 & 3 \\\\\n",
       "\t5 & 2.162 & 0.0 & 0.0 & -1.0 & 1.0 & 11 & 1 & 4 \\\\\n",
       "\t6 & 1.701 & 0.0 & 0.0 & -1.0 & 1.0 & 11 & 1 & 5 \\\\\n",
       "\t7 & 0.258 & 0.147 & 0.0 & -1.0 & 1.0 & 11 & 1 & 6 \\\\\n",
       "\t8 & 0.764 & 0.5 & 0.0 & -1.0 & 1.0 & 11 & 1 & 7 \\\\\n",
       "\t9 & 2.059 & 1.161 & 0.0 & -1.0 & 1.0 & 11 & 1 & 8 \\\\\n",
       "\t10 & 0.295 & 1.879 & 0.0 & -1.0 & 1.0 & 11 & 1 & 9 \\\\\n",
       "\t11 & 0.591 & 1.361 & 0.0 & -1.0 & 1.0 & 11 & 1 & 10 \\\\\n",
       "\t12 & 1.403 & 1.318 & 0.0 & -1.0 & 1.0 & 11 & 1 & 11 \\\\\n",
       "\t13 & 2.389 & 1.133 & 0.0 & -1.0 & 1.0 & 11 & 1 & 12 \\\\\n",
       "\t14 & 2.752 & 1.069 & 0.0 & -1.0 & 1.0 & 11 & 1 & 13 \\\\\n",
       "\t15 & 1.248 & 0.433 & 0.0 & -1.0 & 1.0 & 11 & 1 & 14 \\\\\n",
       "\t16 & 0.861 & 0.078 & 0.0 & -1.0 & 1.0 & 11 & 1 & 15 \\\\\n",
       "\t17 & 1.692 & 0.0 & 0.0 & -1.0 & 1.0 & 11 & 1 & 16 \\\\\n",
       "\t18 & 0.55 & 0.0 & 0.0 & -1.0 & 1.0 & 11 & 1 & 17 \\\\\n",
       "\t19 & 0.871 & 0.0 & 0.0 & -1.0 & 1.0 & 11 & 1 & 18 \\\\\n",
       "\t20 & 2.619 & 0.0 & 0.0 & -1.0 & 1.0 & 11 & 1 & 19 \\\\\n",
       "\t21 & 1.68 & 0.0 & 0.0 & -1.0 & 1.0 & 11 & 1 & 20 \\\\\n",
       "\t22 & 0.543 & 0.0 & 0.0 & -1.0 & 1.0 & 11 & 1 & 21 \\\\\n",
       "\t23 & 0.26 & 0.0 & 0.0 & -1.0 & 1.0 & 11 & 1 & 22 \\\\\n",
       "\t24 & 0.262 & 0.0 & 0.0 & -1.0 & 1.0 & 11 & 1 & 23 \\\\\n",
       "\t$\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m8760×8 DataFrame\u001b[0m\n",
       "\u001b[1m  Row \u001b[0m│\u001b[1m electkwh \u001b[0m\u001b[1m PV_generation \u001b[0m\u001b[1m chargekwh \u001b[0m\u001b[1m h_countdown \u001b[0m\u001b[1m soc_ev   \u001b[0m\u001b[1m month \u001b[0m\u001b[1m day   \u001b[0m\u001b[1m hour  \u001b[0m\n",
       "\u001b[1m      \u001b[0m│\u001b[90m Float64  \u001b[0m\u001b[90m Float64       \u001b[0m\u001b[90m Float64   \u001b[0m\u001b[90m Float64     \u001b[0m\u001b[90m Float64? \u001b[0m\u001b[90m Int64 \u001b[0m\u001b[90m Int64 \u001b[0m\u001b[90m Int64 \u001b[0m\n",
       "──────┼────────────────────────────────────────────────────────────────────────────────\n",
       "    1 │    2.128          0.0          0.0         -1.0       1.0     11      1      0\n",
       "    2 │    0.24           0.0          0.0         -1.0       1.0     11      1      1\n",
       "    3 │    0.722          0.0          0.0         -1.0       1.0     11      1      2\n",
       "    4 │    2.186          0.0          0.0         -1.0       1.0     11      1      3\n",
       "    5 │    2.162          0.0          0.0         -1.0       1.0     11      1      4\n",
       "    6 │    1.701          0.0          0.0         -1.0       1.0     11      1      5\n",
       "    7 │    0.258          0.147        0.0         -1.0       1.0     11      1      6\n",
       "    8 │    0.764          0.5          0.0         -1.0       1.0     11      1      7\n",
       "  ⋮   │    ⋮            ⋮            ⋮           ⋮          ⋮        ⋮      ⋮      ⋮\n",
       " 8754 │    1.69           0.0          0.0         -1.0       1.0     10     31     17\n",
       " 8755 │    0.563          0.0          0.0         -1.0       1.0     10     31     18\n",
       " 8756 │    2.612          0.0          0.0         -1.0       1.0     10     31     19\n",
       " 8757 │    2.288          0.0          0.0         -1.0       1.0     10     31     20\n",
       " 8758 │    0.976          0.0          0.0         -1.0       1.0     10     31     21\n",
       " 8759 │    0.677          0.0          0.0         -1.0       1.0     10     31     22\n",
       " 8760 │    2.005          0.0          0.0         -1.0       1.0     10     31     23\n",
       "\u001b[36m                                                                      8745 rows omitted\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a new DataFrame with the desired structure\n",
    "new_df = DataFrame(\n",
    "    electkwh = df_resampled.e_consumption,\n",
    "    PV_generation = df_resampled.e_production,\n",
    "    chargekwh = df_resampled.e_charger,\n",
    "    h_countdown = df_resampled.h_countdown,\n",
    "    soc_ev = df_resampled.soc_ev,\n",
    "    month = month.(DateTime.(df_resampled.timestamp)),\n",
    "    day = day.(DateTime.(df_resampled.timestamp)),\n",
    "    hour = hour.(DateTime.(df_resampled.timestamp))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7129-element view(::Vector{Union{Missing, Float64}}, [1, 2, 3, 4, 5, 6, 7, 8, 9, 10  …  8751, 8752, 8753, 8754, 8755, 8756, 8757, 8758, 8759, 8760]) with eltype Union{Missing, Float64}:\n",
       " missing\n",
       " missing\n",
       " missing\n",
       " missing\n",
       " missing\n",
       " missing\n",
       " missing\n",
       " missing\n",
       " missing\n",
       " missing\n",
       " ⋮\n",
       " missing\n",
       " missing\n",
       " missing\n",
       " missing\n",
       " missing\n",
       " missing\n",
       " missing\n",
       " missing\n",
       " missing"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Change the type of the chargekwh column to Union{Missing, Float64}\n",
    "new_df.chargekwh = convert(Vector{Union{Missing, Float64}}, new_df.chargekwh)\n",
    "\n",
    "# In every row where h_countdown is -1, set chargekwh to 'missing'\n",
    "new_df[new_df.h_countdown .== -1, :chargekwh] .= missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"data/sonnenCharger06_datafile_all.csv\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Write the new DataFrame to a CSV file in the specified path\n",
    "CSV.write(\"data/sonnen$(ID)_datafile_all.csv\", new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>electkwh</th><th>PV_generation</th><th>chargekwh</th><th>h_countdown</th><th>soc_ev</th><th>month</th><th>day</th><th>hour</th></tr><tr><th></th><th>Float64</th><th>Float64</th><th>Float64?</th><th>Float64</th><th>Float64?</th><th>Int64</th><th>Int64</th><th>Int64</th></tr></thead><tbody><p>8,760 rows × 8 columns</p><tr><th>1</th><td>2.128</td><td>0.0</td><td><em>missing</em></td><td>-1.0</td><td>1.0</td><td>11</td><td>1</td><td>0</td></tr><tr><th>2</th><td>0.24</td><td>0.0</td><td><em>missing</em></td><td>-1.0</td><td>1.0</td><td>11</td><td>1</td><td>1</td></tr><tr><th>3</th><td>0.722</td><td>0.0</td><td><em>missing</em></td><td>-1.0</td><td>1.0</td><td>11</td><td>1</td><td>2</td></tr><tr><th>4</th><td>2.186</td><td>0.0</td><td><em>missing</em></td><td>-1.0</td><td>1.0</td><td>11</td><td>1</td><td>3</td></tr><tr><th>5</th><td>2.162</td><td>0.0</td><td><em>missing</em></td><td>-1.0</td><td>1.0</td><td>11</td><td>1</td><td>4</td></tr><tr><th>6</th><td>1.701</td><td>0.0</td><td><em>missing</em></td><td>-1.0</td><td>1.0</td><td>11</td><td>1</td><td>5</td></tr><tr><th>7</th><td>0.258</td><td>0.147</td><td><em>missing</em></td><td>-1.0</td><td>1.0</td><td>11</td><td>1</td><td>6</td></tr><tr><th>8</th><td>0.764</td><td>0.5</td><td><em>missing</em></td><td>-1.0</td><td>1.0</td><td>11</td><td>1</td><td>7</td></tr><tr><th>9</th><td>2.059</td><td>1.161</td><td><em>missing</em></td><td>-1.0</td><td>1.0</td><td>11</td><td>1</td><td>8</td></tr><tr><th>10</th><td>0.295</td><td>1.879</td><td><em>missing</em></td><td>-1.0</td><td>1.0</td><td>11</td><td>1</td><td>9</td></tr><tr><th>11</th><td>0.591</td><td>1.361</td><td><em>missing</em></td><td>-1.0</td><td>1.0</td><td>11</td><td>1</td><td>10</td></tr><tr><th>12</th><td>1.403</td><td>1.318</td><td><em>missing</em></td><td>-1.0</td><td>1.0</td><td>11</td><td>1</td><td>11</td></tr><tr><th>13</th><td>2.389</td><td>1.133</td><td><em>missing</em></td><td>-1.0</td><td>1.0</td><td>11</td><td>1</td><td>12</td></tr><tr><th>14</th><td>2.752</td><td>1.069</td><td><em>missing</em></td><td>-1.0</td><td>1.0</td><td>11</td><td>1</td><td>13</td></tr><tr><th>15</th><td>1.248</td><td>0.433</td><td><em>missing</em></td><td>-1.0</td><td>1.0</td><td>11</td><td>1</td><td>14</td></tr><tr><th>16</th><td>0.861</td><td>0.078</td><td><em>missing</em></td><td>-1.0</td><td>1.0</td><td>11</td><td>1</td><td>15</td></tr><tr><th>17</th><td>1.692</td><td>0.0</td><td><em>missing</em></td><td>-1.0</td><td>1.0</td><td>11</td><td>1</td><td>16</td></tr><tr><th>18</th><td>0.55</td><td>0.0</td><td><em>missing</em></td><td>-1.0</td><td>1.0</td><td>11</td><td>1</td><td>17</td></tr><tr><th>19</th><td>0.871</td><td>0.0</td><td><em>missing</em></td><td>-1.0</td><td>1.0</td><td>11</td><td>1</td><td>18</td></tr><tr><th>20</th><td>2.619</td><td>0.0</td><td><em>missing</em></td><td>-1.0</td><td>1.0</td><td>11</td><td>1</td><td>19</td></tr><tr><th>21</th><td>1.68</td><td>0.0</td><td><em>missing</em></td><td>-1.0</td><td>1.0</td><td>11</td><td>1</td><td>20</td></tr><tr><th>22</th><td>0.543</td><td>0.0</td><td><em>missing</em></td><td>-1.0</td><td>1.0</td><td>11</td><td>1</td><td>21</td></tr><tr><th>23</th><td>0.26</td><td>0.0</td><td><em>missing</em></td><td>-1.0</td><td>1.0</td><td>11</td><td>1</td><td>22</td></tr><tr><th>24</th><td>0.262</td><td>0.0</td><td><em>missing</em></td><td>-1.0</td><td>1.0</td><td>11</td><td>1</td><td>23</td></tr><tr><th>&vellip;</th><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccccccc}\n",
       "\t& electkwh & PV\\_generation & chargekwh & h\\_countdown & soc\\_ev & month & day & hour\\\\\n",
       "\t\\hline\n",
       "\t& Float64 & Float64 & Float64? & Float64 & Float64? & Int64 & Int64 & Int64\\\\\n",
       "\t\\hline\n",
       "\t1 & 2.128 & 0.0 & \\emph{missing} & -1.0 & 1.0 & 11 & 1 & 0 \\\\\n",
       "\t2 & 0.24 & 0.0 & \\emph{missing} & -1.0 & 1.0 & 11 & 1 & 1 \\\\\n",
       "\t3 & 0.722 & 0.0 & \\emph{missing} & -1.0 & 1.0 & 11 & 1 & 2 \\\\\n",
       "\t4 & 2.186 & 0.0 & \\emph{missing} & -1.0 & 1.0 & 11 & 1 & 3 \\\\\n",
       "\t5 & 2.162 & 0.0 & \\emph{missing} & -1.0 & 1.0 & 11 & 1 & 4 \\\\\n",
       "\t6 & 1.701 & 0.0 & \\emph{missing} & -1.0 & 1.0 & 11 & 1 & 5 \\\\\n",
       "\t7 & 0.258 & 0.147 & \\emph{missing} & -1.0 & 1.0 & 11 & 1 & 6 \\\\\n",
       "\t8 & 0.764 & 0.5 & \\emph{missing} & -1.0 & 1.0 & 11 & 1 & 7 \\\\\n",
       "\t9 & 2.059 & 1.161 & \\emph{missing} & -1.0 & 1.0 & 11 & 1 & 8 \\\\\n",
       "\t10 & 0.295 & 1.879 & \\emph{missing} & -1.0 & 1.0 & 11 & 1 & 9 \\\\\n",
       "\t11 & 0.591 & 1.361 & \\emph{missing} & -1.0 & 1.0 & 11 & 1 & 10 \\\\\n",
       "\t12 & 1.403 & 1.318 & \\emph{missing} & -1.0 & 1.0 & 11 & 1 & 11 \\\\\n",
       "\t13 & 2.389 & 1.133 & \\emph{missing} & -1.0 & 1.0 & 11 & 1 & 12 \\\\\n",
       "\t14 & 2.752 & 1.069 & \\emph{missing} & -1.0 & 1.0 & 11 & 1 & 13 \\\\\n",
       "\t15 & 1.248 & 0.433 & \\emph{missing} & -1.0 & 1.0 & 11 & 1 & 14 \\\\\n",
       "\t16 & 0.861 & 0.078 & \\emph{missing} & -1.0 & 1.0 & 11 & 1 & 15 \\\\\n",
       "\t17 & 1.692 & 0.0 & \\emph{missing} & -1.0 & 1.0 & 11 & 1 & 16 \\\\\n",
       "\t18 & 0.55 & 0.0 & \\emph{missing} & -1.0 & 1.0 & 11 & 1 & 17 \\\\\n",
       "\t19 & 0.871 & 0.0 & \\emph{missing} & -1.0 & 1.0 & 11 & 1 & 18 \\\\\n",
       "\t20 & 2.619 & 0.0 & \\emph{missing} & -1.0 & 1.0 & 11 & 1 & 19 \\\\\n",
       "\t21 & 1.68 & 0.0 & \\emph{missing} & -1.0 & 1.0 & 11 & 1 & 20 \\\\\n",
       "\t22 & 0.543 & 0.0 & \\emph{missing} & -1.0 & 1.0 & 11 & 1 & 21 \\\\\n",
       "\t23 & 0.26 & 0.0 & \\emph{missing} & -1.0 & 1.0 & 11 & 1 & 22 \\\\\n",
       "\t24 & 0.262 & 0.0 & \\emph{missing} & -1.0 & 1.0 & 11 & 1 & 23 \\\\\n",
       "\t$\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m8760×8 DataFrame\u001b[0m\n",
       "\u001b[1m  Row \u001b[0m│\u001b[1m electkwh \u001b[0m\u001b[1m PV_generation \u001b[0m\u001b[1m chargekwh \u001b[0m\u001b[1m h_countdown \u001b[0m\u001b[1m soc_ev   \u001b[0m\u001b[1m month \u001b[0m\u001b[1m day   \u001b[0m\u001b[1m hour  \u001b[0m\n",
       "\u001b[1m      \u001b[0m│\u001b[90m Float64  \u001b[0m\u001b[90m Float64       \u001b[0m\u001b[90m Float64?  \u001b[0m\u001b[90m Float64     \u001b[0m\u001b[90m Float64? \u001b[0m\u001b[90m Int64 \u001b[0m\u001b[90m Int64 \u001b[0m\u001b[90m Int64 \u001b[0m\n",
       "──────┼────────────────────────────────────────────────────────────────────────────────\n",
       "    1 │    2.128          0.0   \u001b[90m   missing \u001b[0m        -1.0       1.0     11      1      0\n",
       "    2 │    0.24           0.0   \u001b[90m   missing \u001b[0m        -1.0       1.0     11      1      1\n",
       "    3 │    0.722          0.0   \u001b[90m   missing \u001b[0m        -1.0       1.0     11      1      2\n",
       "    4 │    2.186          0.0   \u001b[90m   missing \u001b[0m        -1.0       1.0     11      1      3\n",
       "    5 │    2.162          0.0   \u001b[90m   missing \u001b[0m        -1.0       1.0     11      1      4\n",
       "    6 │    1.701          0.0   \u001b[90m   missing \u001b[0m        -1.0       1.0     11      1      5\n",
       "    7 │    0.258          0.147 \u001b[90m   missing \u001b[0m        -1.0       1.0     11      1      6\n",
       "    8 │    0.764          0.5   \u001b[90m   missing \u001b[0m        -1.0       1.0     11      1      7\n",
       "  ⋮   │    ⋮            ⋮            ⋮           ⋮          ⋮        ⋮      ⋮      ⋮\n",
       " 8754 │    1.69           0.0   \u001b[90m   missing \u001b[0m        -1.0       1.0     10     31     17\n",
       " 8755 │    0.563          0.0   \u001b[90m   missing \u001b[0m        -1.0       1.0     10     31     18\n",
       " 8756 │    2.612          0.0   \u001b[90m   missing \u001b[0m        -1.0       1.0     10     31     19\n",
       " 8757 │    2.288          0.0   \u001b[90m   missing \u001b[0m        -1.0       1.0     10     31     20\n",
       " 8758 │    0.976          0.0   \u001b[90m   missing \u001b[0m        -1.0       1.0     10     31     21\n",
       " 8759 │    0.677          0.0   \u001b[90m   missing \u001b[0m        -1.0       1.0     10     31     22\n",
       " 8760 │    2.005          0.0   \u001b[90m   missing \u001b[0m        -1.0       1.0     10     31     23\n",
       "\u001b[36m                                                                      8745 rows omitted\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Input_df = CSV.read(\"data/sonnen$(ID)_datafile_all.csv\", DataFrame);\n",
    "\n",
    "Input_df = new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#describe(Input_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1:8760"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# add new column with number of days\n",
    "Input_df[!, :nday] = 1:nrow(Input_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8760-element Vector{Float64}:\n",
       "  2.128\n",
       "  0.24\n",
       "  0.722\n",
       "  2.186\n",
       "  2.162\n",
       "  1.701\n",
       "  0.11100000000000002\n",
       "  0.264\n",
       "  0.8980000000000001\n",
       " -1.584\n",
       "  ⋮\n",
       " -0.617\n",
       "  0.7210000000000001\n",
       "  1.69\n",
       "  0.5630000000000001\n",
       "  2.612\n",
       "  2.2880000000000003\n",
       "  0.9759999999999999\n",
       "  0.677\n",
       "  2.005"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# calculate residual demand\n",
    "Input_df[!, :d_res] = Input_df[!,:electkwh] + coalesce.(Input_df[!,:chargekwh], 0) - Input_df[!,:PV_generation]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add periodical time representation using cos/sin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add columns with cos and sin values for periodical time values day + month\n",
    "Input_df[!, :hour_cos] = cos.(Input_df[!,:hour] ./ maximum(Input_df[!,:hour]) .* 2*pi);\n",
    "Input_df[!, :hour_sin] = sin.(Input_df[!,:hour] ./ maximum(Input_df[!,:hour]) .* 2*pi);\n",
    "\n",
    "Input_df[!, :month_cos] = cos.(Input_df[!,:month] ./ maximum(Input_df[!,:month]) .* 2*pi);\n",
    "Input_df[!, :month_sin] = sin.(Input_df[!,:month] ./ maximum(Input_df[!,:month]) .* 2*pi);\n",
    "\n",
    "#Input_df[!, :nday_cos] = cos.(Input_df[!,:nday] ./ maximum(Input_df[!,:nday]) .* 2*pi);\n",
    "#Input_df[!, :nday_sin] = sin.(Input_df[!,:nday] ./ maximum(Input_df[!,:nday]) .* 2*pi);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add seasons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Input_df[!, :spring] = (Input_df[!,:month] .>= 3) .* (Input_df[!,:month] .<= 5);\n",
    "Input_df[!, :summer] = (Input_df[!,:month] .>= 6) .* (Input_df[!,:month] .<= 8);\n",
    "Input_df[!, :autumn] = (Input_df[!,:month] .>= 9) .* (Input_df[!,:month] .<= 11);\n",
    "Input_df[!, :winter] = convert.(Bool, (Input_df[!,:month] .>= 12) .+ (Input_df[!,:month] .<= 2));\n",
    "\n",
    "Input_df[!, :season] = ifelse.(Input_df[!,:spring] .== true, 1,\n",
    "                        ifelse.(Input_df[!,:summer] .== true, 2,\n",
    "                        ifelse.(Input_df[!,:autumn] .== true, 3, \n",
    "                        4)));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L"
     ]
    }
   ],
   "source": [
    "print(\"L\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#describe(Input_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add dynamic prices based on Ye et al. 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LU\n",
    "#=\n",
    "function set_dynamic_prices(Input_df)\n",
    "    map(eachrow(Input_df)) do r\n",
    "        if r.month >= 5 && r.month <= 10\n",
    "            if (r.hour >= 6 && r.hour <= 9) || (r.hour >= 16 && r.hour <= 17)\n",
    "                return 0.3f0\n",
    "            elseif (r.hour >= 10 && r.hour <= 15)\n",
    "                return 0.6f0\n",
    "            else\n",
    "                return 0.15f0\n",
    "            end\n",
    "        elseif r.month >= 11 || r.month <= 4\n",
    "            if (r.hour >= 6 && r.hour <= 9) || (r.hour >= 16 && r.hour <= 17)\n",
    "                return 0.6f0\n",
    "            elseif r.hour >= 10 && r.hour <= 15\n",
    "                return 0.3f0\n",
    "            else\n",
    "                return 0.15f0\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "end      =#  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LU\n",
    "#=Input_df[!, \"p_buy\"] = set_dynamic_prices(Input_df);\n",
    "Input_df[!, \"p_sell\"] = 0.5 .* Input_df[!, \"p_buy\"];\n",
    "=#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#LU describe(Input_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract training, testing + evalution data set for summer, winter, both, all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#LU\n",
    "#=# filter summer\n",
    "Input_data_summer = filter(:summer => !=(0), Input_df)\n",
    "describe(Input_data_summer), size(Input_data_summer)\n",
    "=#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=function train_eval_test_split(Input_df)\n",
    "    train = filter(row -> row.day <= 15, Input_df)\n",
    "    eval = filter(row -> row.day > 15 && row.day <= 20, Input_df)\n",
    "    test = filter(row -> row.day > 20, Input_df)\n",
    "    return train, eval, test\n",
    "end=#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=function split_all_data_advanced(Input_df)\n",
    "    # Initialize the split points and the adjustments\n",
    "    splitpoint_adjustments = Dict(\"train\" => 0, \"eval\" => 0, \"test\" => 0)\n",
    "    splitpoints = Dict(\"train\" => 15, \"eval\" => 20)#, \"test\" => lastday(Input_df.date[1]))\n",
    "\n",
    "    # Initialize the data sets\n",
    "    train, eval, test = DataFrame(), DataFrame(), DataFrame()\n",
    "\n",
    "    # Iterate over each month\n",
    "    for month in unique(Input_df[:,:month])\n",
    "        # Adjust the split points based on the previous month's adjustments\n",
    "        #print(\"\\n New month: \", month, \"\\n Splitpoint adjustment: \", splitpoint_adjustments)\n",
    "        splitpoints = Dict(\"train\" => 15, \"eval\" => 20)#, \"test\" => lastday(Input_df.date[1]))\n",
    "        splitpoints[\"train\"] -= splitpoint_adjustments[\"train\"]\n",
    "        splitpoints[\"eval\"] -= splitpoint_adjustments[\"eval\"]\n",
    "        #splitpoints[\"test\"] -= splitpoint_adjustments[\"test\"]\n",
    "\n",
    "        #print(\"\\nSplitpoints: \", splitpoints)\n",
    "\n",
    "        # Reset adjustments for the current month\n",
    "        splitpoint_adjustments = Dict(\"train\" => 0, \"eval\" => 0)#, \"test\" => 0)\n",
    "\n",
    "        # Filter the data for the current month\n",
    "        month_data = filter(row -> row.month == month, Input_df)\n",
    "\n",
    "        # Check and adjust the split points\n",
    "        for (yset_name, yday) in splitpoints\n",
    "            #print(\"\\nmonth: \", month, \"\\nyset_name: \", yset_name, \"\\n yday: \", yday, \"\\n\")\n",
    "            while ((month_data[(month_data.day .== yday) .& (month_data.hour .== 23), :h_countdown][1] > -1) && splitpoint_adjustments[yset_name] <= 4)\n",
    "                print(\"split not ok at month \", month, \", day \", yday, \". Trying at next day.\", \"\\n\")\n",
    "                yday += 1\n",
    "                splitpoint_adjustments[yset_name] += 1\n",
    "                if splitpoint_adjustments[yset_name] == 4\n",
    "                    print(\"\\n Maximum adjustment of 4 days reached! Not ideal splitpoint chosen at month \", month, \". \\n Splitpoint: \", yset_name, \" at \", yday)\n",
    "                end\n",
    "\n",
    "            end\n",
    "            \n",
    "            splitpoints[yset_name] = yday\n",
    "        end\n",
    "\n",
    "        # Split the data for the current month\n",
    "        train = vcat(train, filter(row -> row.day <= splitpoints[\"train\"], month_data))\n",
    "        eval = vcat(eval, filter(row -> row.day > splitpoints[\"train\"] && row.day <= splitpoints[\"eval\"], month_data))\n",
    "        test = vcat(test, filter(row -> row.day > splitpoints[\"eval\"], month_data))\n",
    "    end\n",
    "\n",
    "    return train, eval, test\n",
    "end\n",
    "=#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "split_all_data_advanced_v2 (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function split_all_data_advanced_v2(Input_df)\n",
    "    print(\"start\")\n",
    "    # Initialize the data sets\n",
    "    train = DataFrame()\n",
    "    eval = DataFrame()\n",
    "    test = DataFrame()\n",
    "\n",
    "    # Define the pattern of row counts for each data set\n",
    "    pattern = [(\"test\", 24*10), (\"eval\", 5*24), (\"train\", 15*24)]\n",
    "\n",
    "    splitpoint_adjustments = Dict(\"train\" => 0, \"eval\" => 0, \"test\" => 0)\n",
    "\n",
    "    # Initialize the pattern index\n",
    "    pattern_index = 1\n",
    "\n",
    "    i = 1\n",
    "\n",
    "    # Iterate over the rows of the DataFrame\n",
    "    while i <= size(Input_df, 1)\n",
    "        # Get the current data set name and row count from the pattern\n",
    "        set_name, row_count = pattern[pattern_index]\n",
    "\n",
    "        row_count -= min(splitpoint_adjustments[set_name], 4*24)\n",
    "\n",
    "        #print(\"\\n i: $i, set_name: $set_name, row_count: $row_count, days: $(row_count/24)\")\n",
    "\n",
    "        splitpoint_adjustments[set_name] -= min(splitpoint_adjustments[set_name], 4*24)\n",
    "\n",
    "        print(\"\\n i $i, set_name $set_name, days $(row_count/24), adjustment left: $(splitpoint_adjustments[set_name])\")\n",
    "\n",
    "        while (Input_df[min(i+row_count-1, size(Input_df, 1)), :h_countdown] > -1) #&& splitpoint_adjustments[set_name] <= 3*24)\n",
    "            print(\"\\n i: $i, set_name: $set_name, row_count: $row_count, days: $(row_count/24)\")\n",
    "            print(\"\\n split point not ok at nday \", Input_df[min(i+row_count-1, size(Input_df, 1)), :nday] ,\n",
    "                    \".\\n month $(Input_df[min(i+row_count-1, size(Input_df, 1)), :month]), day $(Input_df[min(i+row_count-1, size(Input_df, 1)), :day]). Trying at next day. \\n\")\n",
    "            row_count += 24\n",
    "            splitpoint_adjustments[set_name] += 24\n",
    "            print(\"Total new splitpoint adjustment for $set_name: $(splitpoint_adjustments[set_name])\")\n",
    "        end\n",
    "\n",
    "        if splitpoint_adjustments[set_name] == 4*24\n",
    "            print(\"\\n Maximum splitpoint adjustment of 4 days reached! Non-ideal splitpoint chosen at nday \", Input_df[min(i+row_count-1, size(Input_df, 1)), :nday] , \" for set \", set_name)\n",
    "        end\n",
    "\n",
    "        print(\"\\n Splitpoint found.\")\n",
    "\n",
    "        # Get the rows for the current data set\n",
    "        \n",
    "\n",
    "        # Add the rows to the appropriate data set\n",
    "        if set_name == \"train\"\n",
    "            rows = Input_df[i:min(i+row_count-1, size(Input_df, 1)), :]\n",
    "            train = vcat(train, rows)\n",
    "\n",
    "            if nrow(train) # TBC: IF train length > 1440 then clip and aso reduce row_count. At the end turn last value of each set c_ev=0.\n",
    "\n",
    "        elseif set_name == \"eval\"\n",
    "            eval = vcat(eval, rows)\n",
    "        else # set_name == \"test\"\n",
    "            test = vcat(test, rows)\n",
    "        end\n",
    "\n",
    "        # Move to the next rows\n",
    "        i = i + row_count\n",
    "\n",
    "        print(\"i end: $i\")\n",
    "\n",
    "        # Move to the next pattern index, or reset to 1 if the end of the pattern is reached\n",
    "        pattern_index = pattern_index % length(pattern) + 1\n",
    "    end\n",
    "\n",
    "    print(\"\\n $splitpoint_adjustments\")\n",
    "\n",
    "    print(\"\\n Length train-data = \", nrow(train), \"\\n Length eval-data = \", nrow(eval), \"\\n Length test-data = \", nrow(test))\n",
    "    \n",
    "    return train, eval, test\n",
    "\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LU\n",
    "#=summer_training, summer_evaluation, summer_testing = train_eval_test_split(Input_data_summer)\n",
    "\n",
    "CSV.write(\"data/$(ID)_summer_train_TOU.csv\", summer_training);\n",
    "CSV.write(\"data/$(ID)_summer_eval_TOU.csv\", summer_evaluation);\n",
    "CSV.write(\"data/$(ID)_summer_test_TOU.csv\", summer_testing);\n",
    "=#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#LU\n",
    "#=# filter winter\n",
    "Input_data_winter = filter(:winter => !=(0), Input_df)\n",
    "describe(Input_data_winter), size(Input_data_winter)\n",
    "=#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LU\n",
    "#=winter_training, winter_evaluation, winter_testing = train_eval_test_split(Input_data_winter)\n",
    "\n",
    "# write data files\n",
    "CSV.write(\"data/$(ID)_winter_train_TOU.csv\", winter_training);\n",
    "CSV.write(\"data/$(ID)_winter_eval_TOU.csv\", winter_evaluation);\n",
    "CSV.write(\"data/$(ID)_winter_test_TOU.csv\", winter_testing);\n",
    "=#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_training, all_evaluation, all_testing = split_all_data_advanced(Input_df)\n",
    "\n",
    "#LU \n",
    "#=\n",
    "# write data files\n",
    "CSV.write(\"data/$(ID)_all_train_TOU.csv\", all_training);\n",
    "CSV.write(\"data/$(ID)_all_eval_TOU.csv\", all_evaluation);\n",
    "CSV.write(\"data/$(ID)_all_test_TOU.csv\", all_testing);\n",
    "=#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LU\n",
    "#describe(vcat(Input_data_winter, Input_data_summer) ), size(vcat(Input_data_winter, Input_data_summer) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LU\n",
    "#=# both seasons split\n",
    "both_training, both_evaluation, both_testing = train_eval_test_split(vcat(Input_data_winter, Input_data_summer))\n",
    "\n",
    "# write data files\n",
    "CSV.write(\"data/$(ID)_both_train_TOU.csv\", both_training);\n",
    "CSV.write(\"data/$(ID)_both_test_TOU.csv\", both_testing);\n",
    "CSV.write(\"data/$(ID)_both_eval_TOU.csv\", both_evaluation);\n",
    "=#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset for fixed prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "Input_df[!, \"p_buy\"] .= 0.3;\n",
    "Input_df[!, \"p_sell\"] .= 0.1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      " i 1, set_name test, days 10.0, adjustment left: 0\n",
      " i: 1, set_name: test, row_count: 240, days: 10.0\n",
      " split point not ok at nday 240.\n",
      " month 11, day 10. Trying at next day. \n",
      "Total new splitpoint adjustment for test: 24\n",
      " Splitpoint found.i end: 265\n",
      " i 265, set_name eval, days 5.0, adjustment left: 0\n",
      " i: 265, set_name: eval, row_count: 120, days: 5.0\n",
      " split point not ok at nday 384.\n",
      " month 11, day 16. Trying at next day. \n",
      "Total new splitpoint adjustment for eval: 24\n",
      " Splitpoint found.i end: 409\n",
      " i 409, set_name train, days 15.0, adjustment left: 0\n",
      " i: 409, set_name: train, row_count: 360, days: 15.0\n",
      " split point not ok at nday 768.\n",
      " month 12, day 2. Trying at next day. \n",
      "Total new splitpoint adjustment for train: 24\n",
      " Splitpoint found.i end: 793\n",
      " i 793, set_name test, days 9.0, adjustment left: 0\n",
      " Splitpoint found.i end: 1009\n",
      " i 1009, set_name eval, days 4.0, adjustment left: 0\n",
      " Splitpoint found.i end: 1105\n",
      " i 1105, set_name train, days 14.0, adjustment left: 0\n",
      " Splitpoint found.i end: 1441\n",
      " i 1441, set_name test, days 10.0, adjustment left: 0\n",
      " Splitpoint found.i end: 1681\n",
      " i 1681, set_name eval, days 5.0, adjustment left: 0\n",
      " Splitpoint found.i end: 1801\n",
      " i 1801, set_name train, days 15.0, adjustment left: 0\n",
      " i: 1801, set_name: train, row_count: 360, days: 15.0\n",
      " split point not ok at nday 2160.\n",
      " month 1, day 29. Trying at next day. \n",
      "Total new splitpoint adjustment for train: 24\n",
      " i: 1801, set_name: train, row_count: 384, days: 16.0\n",
      " split point not ok at nday 2184.\n",
      " month 1, day 30. Trying at next day. \n",
      "Total new splitpoint adjustment for train: 48\n",
      " i: 1801, set_name: train, row_count: 408, days: 17.0\n",
      " split point not ok at nday 2208.\n",
      " month 1, day 31. Trying at next day. \n",
      "Total new splitpoint adjustment for train: 72\n",
      " i: 1801, set_name: train, row_count: 432, days: 18.0\n",
      " split point not ok at nday 2232.\n",
      " month 2, day 1. Trying at next day. \n",
      "Total new splitpoint adjustment for train: 96\n",
      " Maximum splitpoint adjustment of 4 days reached! Non-ideal splitpoint chosen at nday 2256 for set train\n",
      " Splitpoint found.i end: 2257\n",
      " i 2257, set_name test, days 10.0, adjustment left: 0\n",
      " Splitpoint found.i end: 2497\n",
      " i 2497, set_name eval, days 5.0, adjustment left: 0\n",
      " Splitpoint found.i end: 2617\n",
      " i 2617, set_name train, days 11.0, adjustment left: 0\n",
      " Splitpoint found.i end: 2881\n",
      " i 2881, set_name test, days 10.0, adjustment left: 0\n",
      " i: 2881, set_name: test, row_count: 240, days: 10.0\n",
      " split point not ok at nday 3120.\n",
      " month 3, day 10. Trying at next day. \n",
      "Total new splitpoint adjustment for test: 24\n",
      " Splitpoint found.i end: 3145\n",
      " i 3145, set_name eval, days 5.0, adjustment left: 0\n",
      " i: 3145, set_name: eval, row_count: 120, days: 5.0\n",
      " split point not ok at nday 3264.\n",
      " month 3, day 16. Trying at next day. \n",
      "Total new splitpoint adjustment for eval: 24\n",
      " Splitpoint found.i end: 3289\n",
      " i 3289, set_name train, days 15.0, adjustment left: 0\n",
      " Splitpoint found.i end: 3649\n",
      " i 3649, set_name test, days 9.0, adjustment left: 0\n",
      " i: 3649, set_name: test, row_count: 216, days: 9.0\n",
      " split point not ok at nday 3864.\n",
      " month 4, day 11. Trying at next day. \n",
      "Total new splitpoint adjustment for test: 24\n",
      " i: 3649, set_name: test, row_count: 240, days: 10.0\n",
      " split point not ok at nday 3888.\n",
      " month 4, day 12. Trying at next day. \n",
      "Total new splitpoint adjustment for test: 48\n",
      " Splitpoint found.i end: 3913\n",
      " i 3913, set_name eval, days 4.0, adjustment left: 0\n",
      " Splitpoint found.i end: 4009\n",
      " i 4009, set_name train, days 15.0, adjustment left: 0\n",
      " Splitpoint found.i end: 4369\n",
      " i 4369, set_name test, days 8.0, adjustment left: 0\n",
      " Splitpoint found.i end: 4561\n",
      " i 4561, set_name eval, days 5.0, adjustment left: 0\n",
      " Splitpoint found.i end: 4681\n",
      " i 4681, set_name train, days 15.0, adjustment left: 0\n",
      " i: 4681, set_name: train, row_count: 360, days: 15.0\n",
      " split point not ok at nday 5040.\n",
      " month 5, day 30. Trying at next day. \n",
      "Total new splitpoint adjustment for train: 24\n",
      " i: 4681, set_name: train, row_count: 384, days: 16.0\n",
      " split point not ok at nday 5064.\n",
      " month 5, day 31. Trying at next day. \n",
      "Total new splitpoint adjustment for train: 48\n",
      " i: 4681, set_name: train, row_count: 408, days: 17.0\n",
      " split point not ok at nday 5088.\n",
      " month 6, day 1. Trying at next day. \n",
      "Total new splitpoint adjustment for train: 72\n",
      " Splitpoint found.i end: 5113\n",
      " i 5113, set_name test, days 10.0, adjustment left: 0\n",
      " Splitpoint found.i end: 5353\n",
      " i 5353, set_name eval, days 5.0, adjustment left: 0\n",
      " Splitpoint found.i end: 5473\n",
      " i 5473, set_name train, days 12.0, adjustment left: 0\n",
      " Splitpoint found.i end: 5761\n",
      " i 5761, set_name test, days 10.0, adjustment left: 0\n",
      " Splitpoint found.i end: 6001\n",
      " i 6001, set_name eval, days 5.0, adjustment left: 0\n",
      " Splitpoint found.i end: 6121\n",
      " i 6121, set_name train, days 15.0, adjustment left: 0\n",
      " Splitpoint found.i end: 6481\n",
      " i 6481, set_name test, days 10.0, adjustment left: 0\n",
      " Splitpoint found.i end: 6721\n",
      " i 6721, set_name eval, days 5.0, adjustment left: 0\n",
      " Splitpoint found.i end: 6841\n",
      " i 6841, set_name train, days 15.0, adjustment left: 0\n",
      " Splitpoint found.i end: 7201\n",
      " i 7201, set_name test, days 10.0, adjustment left: 0\n",
      " Splitpoint found.i end: 7441\n",
      " i 7441, set_name eval, days 5.0, adjustment left: 0\n",
      " Splitpoint found.i end: 7561\n",
      " i 7561, set_name train, days 15.0, adjustment left: 0\n",
      " Splitpoint found.i end: 7921\n",
      " i 7921, set_name test, days 10.0, adjustment left: 0\n",
      " i: 7921, set_name: test, row_count: 240, days: 10.0\n",
      " split point not ok at nday 8160.\n",
      " month 10, day 7. Trying at next day. \n",
      "Total new splitpoint adjustment for test: 24\n",
      " Splitpoint found.i end: 8185\n",
      " i 8185, set_name eval, days 5.0, adjustment left: 0\n",
      " i: 8185, set_name: eval, row_count: 120, days: 5.0\n",
      " split point not ok at nday 8304.\n",
      " month 10, day 13. Trying at next day. \n",
      "Total new splitpoint adjustment for eval: 24\n",
      " Splitpoint found.i end: 8329\n",
      " i 8329, set_name train, days 15.0, adjustment left: 0\n",
      " i: 8329, set_name: train, row_count: 360, days: 15.0\n",
      " split point not ok at nday 8688.\n",
      " month 10, day 29. Trying at next day. \n",
      "Total new splitpoint adjustment for train: 24\n",
      " Splitpoint found.i end: 8713\n",
      " i 8713, set_name test, days 9.0, adjustment left: 0\n",
      " Splitpoint found.i end: 8929\n",
      " Dict(\"test\" => 0, \"train\" => 24, \"eval\" => 24)\n",
      " Length train-data = 4344\n",
      " Length eval-data = 1464\n",
      " Length test-data = 2952train-data length: 4344\n",
      "eval-data length: 1464\n",
      "test-data length: 2952\n"
     ]
    }
   ],
   "source": [
    "all_training, all_evaluation, all_testing = split_all_data_advanced_v2(Input_df)\n",
    "for (set, df) in [(\"train\" , all_training), (\"eval\", all_evaluation), (\"test\", all_testing)]\n",
    "    print(set, \"-data length: \", nrow(df), \"\\n\")\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LU\n",
    "#Input_data_summer = filter(:summer => !=(0), Input_df);\n",
    "#Input_data_winter = filter(:winter => !=(0), Input_df);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LU summer_training, summer_evaluation, summer_testing = train_eval_test_split(Input_data_summer);\n",
    "#LU winter_training, winter_evaluation, winter_testing = train_eval_test_split(Input_data_winter);\n",
    "#LU all_training, all_evaluation, all_testing = train_eval_test_split(Input_df);\n",
    "#LU both_training, both_evaluation, both_testing = train_eval_test_split(vcat(Input_data_winter, Input_data_summer));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"data/Charger06_all_eval_fix.csv\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#LU\n",
    "#=CSV.write(\"data/$(ID)_both_train_fix.csv\", both_training);\n",
    "CSV.write(\"data/$(ID)_both_test_fix.csv\", both_testing);\n",
    "CSV.write(\"data/$(ID)_both_eval_fix.csv\", both_evaluation);=#\n",
    "\n",
    "CSV.write(\"data/$(ID)_all_train_fix.csv\", all_training);\n",
    "CSV.write(\"data/$(ID)_all_test_fix.csv\", all_testing);\n",
    "CSV.write(\"data/$(ID)_all_eval_fix.csv\", all_evaluation);\n",
    "\n",
    "#LU\n",
    "#=CSV.write(\"data/$(ID)_summer_train_fix.csv\", summer_training);\n",
    "CSV.write(\"data/$(ID)_summer_test_fix.csv\", summer_testing);\n",
    "CSV.write(\"data/$(ID)_summer_eval_fix.csv\", summer_evaluation);\n",
    "CSV.write(\"data/$(ID)_winter_train_fix.csv\", winter_training);\n",
    "CSV.write(\"data/$(ID)_winter_test_fix.csv\", winter_testing);\n",
    "CSV.write(\"data/$(ID)_winter_eval_fix.csv\", winter_evaluation);\n",
    "=#"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Julia 1.6.1",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
